{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from  ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_qasrl = pd.read_csv(\"../../data_to_annotate/gold/combined_data/processed_qasrl_arb_cls_gold.csv\")\n",
    "scu_duc_sents = pd.read_csv(\"../../data_to_annotate/gold/DUC06/qa_data/gold_pyr_pre_qasrl.csv\")\n",
    "ebc_sents = pd.read_csv(\"../../data_to_annotate/gold/ECB/qa_data/gold_ecb_pre_qasrl.csv\")\n",
    "#sents2scu = pd.read_csv(\"../data_to_annotate/gold/DUC06/qa_data/sentences_2_scu_index.csv\")\n",
    "with open(\"../../data_to_annotate/gold/DUC06/qa_data/sentences_2_scu_index.csv\", \"r\") as f:\n",
    "    conts = f.read()\n",
    "    sent2scu = literal_eval(conts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating candidate pairs for alignment, based on scu_index for the pyramid data and document for ecb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def pair_up_scus(df):\n",
    "    grouped = df.groupby([\"document\",\"scu_index\"])\n",
    "    pairs = []\n",
    "    for i,g in grouped:\n",
    "        pairs.extend(create_candidate_pairs(g))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def pair_up_ecbs(df):\n",
    "    grouped = df.groupby(\"document\")\n",
    "    pairs = []\n",
    "    for i,g in grouped:\n",
    "        pairs.extend(create_candidate_pairs(g))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def create_candidate_pairs(df):\n",
    "    pairs = []\n",
    "    for subset in itertools.combinations(df.qasrl_id.value_counts().keys(), 2):\n",
    "        print(subset)\n",
    "        pairs.append((subset[0], subset[1]))\n",
    "    print()\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scu_pairs = pair_up_scus(scu_duc_sents)\n",
    "ecb_pairs = pair_up_ecbs(ebc_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scu_pairs) + len(ecb_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting together qasrl annotations for each qasrl_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gold_qasrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order: \"qa_uuid\",\"verb\",\"verbidx\", \"question\",\"answer\",\"answer_range\"\n",
    "grouped = gold_qasrl.groupby(\"qasrl_id\")\n",
    "qas = {}\n",
    "for i,g in grouped:\n",
    "    qa_zip = list(zip(g[\"qa_uuid\"].tolist(),  g[\"verb\"].tolist(), g[\"verb_idx\"].tolist(),g[\"question\"].tolist(), g[\"answer\"].tolist()))\n",
    "    qas[g[\"qasrl_id\"].iloc[0]] = qa_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAs is a dictionary, mapping qasrl_id -> list of (\"qa_uuid\",\"verb\",\"verbidx\", \"question\",\"answer\",\"answer_range\") tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qas_final = qas.copy()\n",
    "for k,v in qas.items():\n",
    "    new_v = []\n",
    "    for item in v:\n",
    "        new_v.append(list(item))\n",
    "    qas_final[k] = new_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there's about 6 sentences that had no predicates extracted, therefore we remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_qasrl.qasrl_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_sents = pd.read_csv(\"../../data_to_annotate/gold/combined_data/ecb_duc_pre_qasrl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_qas = list(orig_sents[~orig_sents.qasrl_id.isin(list(gold_qasrl.qasrl_id))][\"qasrl_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_qas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now go through all pairs and create a csv that contains all the information. Sent1, Sent2, and qasrl annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data columns for Mturk -\n",
    "    [\"qasrl_id_1\", \"sent1\",\"prev_text_1\",\"qa_1\",\"qasrl_id_2\", \"sent2\", \"prev_text_2\"qa_2\", \"qasrl_id_1_unique_annots\", \"qasrl_id_2_unique_annots\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCU data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    gold_qasrl - qas for gold data\n",
    "    scu_duc_sents - pyr sentences\n",
    "    ebc_sents - ecb sents\n",
    "    sent2scu - pyr sent to scu index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "sent2qasrl = defaultdict()\n",
    "for i,row in scu_duc_sents.iterrows():\n",
    "    if row[\"sentence\"] in sent2qasrl:\n",
    "        sent2qasrl[row[\"sentence\"]].append(row[\"qasrl_id\"])\n",
    "    else: sent2qasrl[row[\"sentence\"]] = [row[\"qasrl_id\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_scu_data = []\n",
    "removed_pairs = []\n",
    "for p in scu_pairs:\n",
    "    hit = set() #represents an scu hit\n",
    "    df1 = scu_duc_sents[scu_duc_sents.qasrl_id == p[0]]\n",
    "    df2 = scu_duc_sents[scu_duc_sents.qasrl_id == p[1]]\n",
    "    \n",
    "    qaids_1_list = sent2qasrl[df1.sentence.iloc[0]]\n",
    "    qaids_2_list = sent2qasrl[df2.sentence.iloc[0]]\n",
    "    \n",
    "    qasrl_id_used = None\n",
    "    for qaid in qaids_1_list:\n",
    "        if qaid in qas_final:\n",
    "            qasrl_id_used = qaid\n",
    "            break\n",
    "    \n",
    "    qasr2_id_used = None\n",
    "    for qaid in qaids_2_list:\n",
    "        if qaid in qas_final:\n",
    "            qasr2_id_used = qaid\n",
    "            break\n",
    "\n",
    "    if qasrl_id_used == None or qasr2_id_used == None:\n",
    "        removed_pairs.append((p[0], p[1], qaids_1_list, qaids_2_list))\n",
    "        continue\n",
    "    \n",
    "    qa1 = qas_final[qasrl_id_used]\n",
    "    qa2 = qas_final[qasr2_id_used]\n",
    "\n",
    "    #[\"qasrl_id_1\", \"sent1\",\"prev_text_1\",\"qa_1\",\"qasrl_id_2\", \"sent2\", \"prev_text_2\"qa_2\", \"qasrl_id_1_unique_annots\", \"qasrl_id_2_unique_annots\" ]\n",
    "    mturk_scu_data.append((p[0], df1.sentence.iloc[0], df1.prev_text.iloc[0], qa1, p[1], df2.sentence.iloc[0], df2.prev_text.iloc[0], qa2, qasrl_id_used, qasr2_id_used))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we'll do the same for ecb data, except theres no duplicates so less work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_ecb_data = []\n",
    "\n",
    "for p in ecb_pairs:\n",
    "    if p[0] in to_remove_qas or p[1] in to_remove_qas:\n",
    "        removed_pairs.append((p[0], p[1], None, None))\n",
    "        continue\n",
    "\n",
    "    hit = set() #represents an scu hit\n",
    "    df1 = ebc_sents[ebc_sents.qasrl_id == p[0]]\n",
    "    df2 = ebc_sents[ebc_sents.qasrl_id == p[1]]\n",
    "    \n",
    "    qa1 = qas_final[p[0]]\n",
    "    qa2 = qas_final[p[1]]\n",
    "\n",
    "    #[\"qasrl_id_1\", \"sent1\",\"prev_text_1\",\"qa_1\",\"qasrl_id_2\", \"sent2\", \"prev_text_2\"qa_2\", \"qasrl_id_1_unique_annots\", \"qasrl_id_2_unique_annots\" ]\n",
    "    mturk_ecb_data.append((p[0], df1.sentence.iloc[0], df1.prev_sentence.iloc[0], qa1, p[1], df2.sentence.iloc[0], df2.prev_sentence.iloc[0], qa2, None, None))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_pairs_lost = pd.DataFrame(removed_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(removed_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_pairs_lost.columns = [\"qasrl_id1\", \"qasrl_id2\", \"all_qaids_1\", \"all_qaids_2\"]\n",
    "removed_pairs_lost.to_csv(\"removed_pairs_lost.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We removed {} number of pairs, due to them having no predicates when parsing for qas\".format(len(removed_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} pair intances from DUC data, and {} pair instances from ecb data; total of {}\".format(len(mturk_scu_data), len(mturk_ecb_data), len(mturk_scu_data) + len(mturk_ecb_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_scu_data.extend(mturk_ecb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_data = mturk_scu_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mturk_data) #final number of pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we create a data from from all of our collected rows, which correspond to a HIT on mturk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_df = pd.DataFrame(mturk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_df.columns = [\"qasrl_id_1\", \"sent1\",\"prev_text_1\",\"qa_1\",\"qasrl_id_2\", \"sent2\", \"prev_text_2\", \"qa_2\", \"qasrl_id_1_unique_annots\", \"qasrl_id_2_unique_annots\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk_df.to_csv(\"mturk_gold_prepared_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfortunately we're not exactly done. We need to prepare a sentence suitable for the html, one that has the verbs bolded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process text for html view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "mturk = pd.read_csv(\"mturk_gold_prepared_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_return(val):\n",
    "    try:\n",
    "        return literal_eval(val)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk[\"qa_1\"] = mturk[\"qa_1\"].apply(literal_return)\n",
    "mturk[\"qa_2\"] = mturk[\"qa_2\"].apply(literal_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - if a previous sentence is empty, this means the actual sentence is the first of its document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1_html = []\n",
    "sent2_html = []\n",
    "qa1_html = []\n",
    "qa2_html = []\n",
    "for i, row in df.iterrows():\n",
    "    verbs = get_verbs(row[\"qa_1\"])\n",
    "    sent1 = row[\"sent1\"]\n",
    "    nsent = find_verb(sent1, verbs)\n",
    "    sent1_html.append(nsent)\n",
    "    \n",
    "    verbs = get_verbs(row[\"qa_2\"])\n",
    "    sent2 = row[\"sent2\"]\n",
    "    nsent = find_verb(sent2, verbs)\n",
    "    sent2_html.append(nsent)\n",
    "\n",
    "mturk[\"sent1_html\"] = sent1_html\n",
    "mturk[\"sent2_html\"] = sent2_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_verbs(qal):\n",
    "    verb_set = set()\n",
    "    for qa in qal:\n",
    "        verb_set.add((qa[1], qa[2])) #verb, verb_idx\n",
    "    return verb_set\n",
    "\n",
    "def find_verb(sent, verbs):\n",
    "    for verb in verbs:\n",
    "        if verb[0].lower() in sent.lower():\n",
    "            sent = sent.lower().replace(verb[0].lower(), \"<strong>\"+verb[0].lower()+\"</strong>\")\n",
    "            '''\n",
    "            numVerbs = re.findall(verb[0], sent)\n",
    "            if len(numVerbs) == 1:\n",
    "                sent.replace(verb[0], \"<strong>\"+verb[0]+\"</strong>\")\n",
    "                return sent\n",
    "            else:\n",
    "                nsent = re.findall(r\"[\\w']+|[.,!?;]\", sent)\n",
    "                all_verbs = [m.start() for m in re.finditer('test', 'test test test test')]\n",
    "                choice_num = 0\n",
    "                for i, token in enumerate(nsent):\n",
    "                    if token == verb[0] and i != verb[1]:\n",
    "                        choice_num +=1\n",
    "                        continue\n",
    "                    if i == verb[1]:\n",
    "                        #replace substring only on the choice_num'th occurrence\n",
    "            print(nsent)\n",
    "            print (re.findall(verb[0], sent))\n",
    "            '''\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally we are done preparing cls data for Mechanical Turk!\n",
    "\n",
    "#### lets take a look at an example row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "mturk.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mturk.to_csv(\"mturk_gold_prepared_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# once more step! in a text editor, you must replace all ' to \\', since mturl loads the csv, without properly rendering complex objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../preparing_cls/cls_gold_trap_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qasrl_id_1', 'sent1', 'prev_text_1', 'qa_1', 'qasrl_id_2', 'sent2',\n",
       "       'prev_text_2', 'qa_2', 'qasrl_id_1_unique_annots',\n",
       "       'qasrl_id_2_unique_annots', 'sent1_html', 'sent2_html'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_empty_prevs(row):\n",
    "    if row['prev_text_1'] == \"---------------\" or \"\":\n",
    "        row[\"prev_text_1\"] = \"NA\"\n",
    "    if row['prev_text_2'] == \"---------------\" or \"\":\n",
    "        row[\"prev_text_2\"] = \"NA\" \n",
    "    if type(row[\"prev_text_2\"]) != str:\n",
    "        row[\"prev_text_2\"] = \"NA\"\n",
    "    if type(row[\"prev_text_1\"]) != str:\n",
    "        row[\"prev_text_1\"] = \"NA\"\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: replace_empty_prevs(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"qa_1\"] = df[\"qa_1\"].apply(lambda x: eval(x))\n",
    "df[\"qa_2\"] = df[\"qa_2\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_verbs(qal):\n",
    "    verb_set = set()\n",
    "    for qa in qal:\n",
    "        verb_set.add((qa[1], qa[2])) #verb, verb_idx\n",
    "    return verb_set\n",
    "\n",
    "def find_verbs(sent, verbs):\n",
    "    for verb in verbs:\n",
    "        for token in sent.split(\" \"):\n",
    "            if verb[0].lower() == token.lower():\n",
    "                sent = sent.replace(token, \"<strong>\"+token+\"</strong>\")\n",
    "            '''\n",
    "            numVerbs = re.findall(verb[0], sent)\n",
    "            if len(numVerbs) == 1:\n",
    "                sent.replace(verb[0], \"<strong>\"+verb[0]+\"</strong>\")\n",
    "                return sent\n",
    "            else:\n",
    "                nsent = re.findall(r\"[\\w']+|[.,!?;]\", sent)\n",
    "                all_verbs = [m.start() for m in re.finditer('test', 'test test test test')]\n",
    "                choice_num = 0\n",
    "                for i, token in enumerate(nsent):\n",
    "                    if token == verb[0] and i != verb[1]:\n",
    "                        choice_num +=1\n",
    "                        continue\n",
    "                    if i == verb[1]:\n",
    "                        #replace substring only on the choice_num'th occurrence\n",
    "            print(nsent)\n",
    "            print (re.findall(verb[0], sent))\n",
    "            '''\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1_html = []\n",
    "sent2_html = []\n",
    "qa1_html = []\n",
    "qa2_html = []\n",
    "for i, row in df.iterrows():\n",
    "    verbs = get_verbs(row[\"qa_1\"])\n",
    "    sent1 = row[\"sent1\"]\n",
    "    nsent = find_verbs(sent1, verbs)\n",
    "    sent1_html.append(nsent)\n",
    "    \n",
    "    verbs = get_verbs(row[\"qa_2\"])\n",
    "    sent2 = row[\"sent2\"]\n",
    "    nsent = find_verbs(sent2, verbs)\n",
    "    sent2_html.append(nsent)\n",
    "\n",
    "df[\"sent1_html\"] = sent1_html\n",
    "df[\"sent2_html\"] = sent2_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Drug and alcohol addiction, domestic violence,...\n",
       "1    International help with wetland restoration ha...\n",
       "2    The World Bank is <strong>approving</strong> l...\n",
       "3    In the US, new regulations were <strong>issued...\n",
       "4    HMP-33, a ginger extract, and SAM-e also <stro...\n",
       "Name: sent1_html, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sent1_html\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cls_gold_trap_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noticed QASRL also has the tags: \"LSB and RSB instead of '['']'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_mturk_gold_cls_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"qa_1\"] = df[\"qa_1\"].apply(lambda x: eval(x))\n",
    "df[\"qa_2\"] = df[\"qa_2\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_brackets(qa):#5_5ecbplus_7\n",
    "    for q in qa:\n",
    "        if \"-LSB-\" in q[4]:\n",
    "            q[4] = q[4].replace(\"-LSB-\", \"[\")\n",
    "        if \"-RSB-\" in q[4]:\n",
    "            q[4] = q[4].replace(\"-RSB-\", \"]\")\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"qa_2\"] = df[\"qa_2\"].apply(lambda x: replace_brackets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113    [[601, canned, 7, Where did someone can someone?, Up the coast], [602, canned, 7, Who canned someone?, the Philly Sixers], [603, canned, 7, Who did someone can?, Jim O'Brien], [604, canned, 7, Why did someone can someone?, had been under fire all season], [605, hired, 21, How was someone hired by someone?, quickly], [606, hired, 21, Who hired someone?, the Philly Sixers], [607, hired, 21, Who was hired by someone?, Mo Cheeks], [608, hired, 21, Why has someone been hired?, canned Jim O'Brien [ who had been under fire all season ]]]\n",
      "Name: qa_2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[df.qasrl_id_2 == \"5_5ecbplus_2\"][\"qa_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_mturk_gold_cls_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
